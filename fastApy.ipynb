{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmHPfyiiOQkB",
        "outputId": "bfaae250-001d-4120-d1c3-b5ca0377325b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Paso 1: InstalaciÃ³n de librerÃ­as necesarias\n",
        "!pip install fastapi uvicorn nest_asyncio pyngrok scikit-learn joblib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Entrenar y guardar el modelo\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Guardar modelo y nombres de clases\n",
        "joblib.dump((model, target_names), \"model.pkl\")\n",
        "print(\"Modelo y nombres de clase guardados como model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F_cSVpFOwMe",
        "outputId": "190d8bcd-a040-4d3a-a675-638daa1b12ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo y nombres de clase guardados como model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Crear la API FastAPI con salida detallada\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "app = FastAPI(title=\"Servicio de ClasificaciÃ³n Iris\")\n",
        "\n",
        "# Cargar modelo y clases\n",
        "model, class_names = joblib.load(\"model.pkl\")\n",
        "\n",
        "class InputData(BaseModel):\n",
        "    features: list[float]\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(data: InputData):\n",
        "    try:\n",
        "        X = np.array(data.features).reshape(1, -1)\n",
        "        prediction = model.predict(X)[0]\n",
        "        proba = model.predict_proba(X)[0]\n",
        "\n",
        "        result = {\n",
        "            \"predicted_class\": int(prediction),\n",
        "            \"class_name\": class_names[prediction],\n",
        "            \"probabilities\": {\n",
        "                class_names[i]: f\"{round(p * 100, 2)}%\" for i, p in enumerate(proba)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        logging.info(f\"Entrada: {data.features} -> PredicciÃ³n: {result}\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error en la predicciÃ³n: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Error interno del modelo\")"
      ],
      "metadata": {
        "id": "NnKc8q7tOwEM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Ejecutar FastAPI con ngrok y manejo de errores\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import socket\n",
        "import os\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "!ngrok config add-authtoken 2uxqXsEpzKAdvsgXYMMk6JZmRkD_2a3ZiXFm2NechpL1hGYQt\n",
        "\n",
        "def kill_process_on_port(port):\n",
        "    try:\n",
        "        result = os.popen(f\"lsof -i :{port}\").read()\n",
        "        lines = result.strip().split(\"\\\\n\")\n",
        "        if len(lines) > 1:\n",
        "            pid = int(lines[1].split()[1])\n",
        "            os.kill(pid, 9)\n",
        "            print(f\"Proceso en el puerto {port} eliminado.\")\n",
        "        else:\n",
        "            print(f\"â„¹ï¸ No hay procesos corriendo en el puerto {port}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error matando proceso: {e}\")\n",
        "\n",
        "def get_free_port(start=7860, end=8081):\n",
        "    for port in range(start, end):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            try:\n",
        "                s.bind((\"127.0.0.1\", port))\n",
        "                return port\n",
        "            except OSError:\n",
        "                continue\n",
        "    raise RuntimeError(\"No hay puertos libres disponibles\")\n",
        "\n",
        "try:\n",
        "    port = get_free_port()\n",
        "    kill_process_on_port(port)\n",
        "\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "        print(\"ðŸ”Œ TÃºneles ngrok anteriores cerrados.\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    time.sleep(2)\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\"Tu API estÃ¡ disponible en: {public_url}\")\n",
        "\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error al iniciar el servidor o tÃºnel ngrok:\")\n",
        "    print(str(e))\n",
        "    print(\"Cierra sesiones activas desde https://dashboard.ngrok.com/agents si es necesario.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgjbzO_iOv8z",
        "outputId": "995af3f1-ab0b-4144-a2aa-a93cbf1c452c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "â„¹ï¸ No hay procesos corriendo en el puerto 7860.\n",
            "ðŸ”Œ TÃºneles ngrok anteriores cerrados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [686]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Tu API estÃ¡ disponible en: NgrokTunnel: \"https://d1cc-34-44-31-207.ngrok-free.app\" -> \"http://localhost:7860\"\n",
            "INFO:     223.27.115.62:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     223.27.115.62:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     223.27.115.62:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     223.27.115.62:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [686]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5EkJD6YlOvzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yI9w1dQOvq7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}